{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet512_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6_GfzOsBERg",
        "outputId": "a13671e9-948c-4015-a262-dfdbeaca2524"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/gdrive')\r\n",
        "%cd /gdrive/MyDrive/CV_FinalProject/Dungmn/\r\n",
        "print(\"===============\")\r\n",
        "!ls "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive/.shortcut-targets-by-id/1rvVQN848IG4yYS2DU7AHiKiDnungjDoK/CV_FinalProject/Dungmn\n",
            "===============\n",
            "coco\t\t\t\tpytorch-tutorial\n",
            "coco-caption\t\t\tResnet512_Attention_LSTM.ipynb\n",
            "correct_captions_val.csv\tResnet512_LSTM.ipynb\n",
            "Data\t\t\t\tresult\n",
            "eval.ipynb\t\t\tshow_attend_and_tell_pytorch\n",
            "Image_Captioning_PhoBert.ipynb\ttest.csv\n",
            "image_captioning_pytorch\ttrain_UITViIC.csv\n",
            "Image-Captions\t\t\ttrain_UITViIC_raw.csv.gsheet\n",
            "preprocessing.ipynb\t\ttransformers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkLNoQCmgitb"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "mn78A59hLBv4",
        "outputId": "584a1ada-9573-451f-f8f2-d75ad171d8df"
      },
      "source": [
        "!pip install torchvision==0.4.0\r\n",
        "!pip install pillow==6.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchvision==0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/e6/a564eba563f7ff53aa7318ff6aaa5bd8385cbda39ed55ba471e95af27d19/torchvision-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (8.8MB)\n",
            "\u001b[K     |████████████████████████████████| 8.8MB 5.2MB/s \n",
            "\u001b[?25hCollecting torch==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/57/d5cceb0799c06733eefce80c395459f28970ebb9e896846ce96ab579a3f1/torch-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (748.8MB)\n",
            "\u001b[K     |████████████████████████████████| 748.9MB 17kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.0) (1.15.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.0) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.7.0+cu101\n",
            "    Uninstalling torch-1.7.0+cu101:\n",
            "      Successfully uninstalled torch-1.7.0+cu101\n",
            "  Found existing installation: torchvision 0.8.1+cu101\n",
            "    Uninstalling torchvision-0.8.1+cu101:\n",
            "      Successfully uninstalled torchvision-0.8.1+cu101\n",
            "Successfully installed torch-1.2.0 torchvision-0.4.0\n",
            "Collecting pillow==6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/41/db6dec65ddbc176a59b89485e8cc136a433ed9c6397b6bfe2cd38412051e/Pillow-6.1.0-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 6.6MB/s \n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pillow\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "Successfully installed pillow-6.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8asYYcCF8Y1",
        "outputId": "1533a8c3-fcee-4c79-bdb8-dbb2764466b8"
      },
      "source": [
        "# !git clone https://github.com/huggingface/transformers.git\r\n",
        "# %cd transformers\r\n",
        "# !pip install --upgrade .\r\n",
        "# %cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 62974, done.\u001b[K\n",
            "remote: Total 62974 (delta 0), reused 0 (delta 0), pack-reused 62974\u001b[K\n",
            "Receiving objects: 100% (62974/62974), 48.00 MiB | 5.23 MiB/s, done.\n",
            "Resolving deltas: 100% (44621/44621), done.\n",
            "Checking out files: 100% (1071/1071), done.\n",
            "/gdrive/.shortcut-targets-by-id/1rvVQN848IG4yYS2DU7AHiKiDnungjDoK/CV_FinalProject/Dungmn/transformers\n",
            "Processing /gdrive/.shortcut-targets-by-id/1rvVQN848IG4yYS2DU7AHiKiDnungjDoK/CV_FinalProject/Dungmn/transformers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==4.4.0.dev0) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.4.0.dev0) (3.4.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers==4.4.0.dev0) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==4.4.0.dev0) (0.8)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==4.4.0.dev0) (3.0.12)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/5b/44baae602e0a30bcc53fbdbc60bd940c15e143d252d658dfdefce736ece5/tokenizers-0.10.1-cp36-cp36m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 15.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==4.4.0.dev0) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==4.4.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers==4.4.0.dev0) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==4.4.0.dev0) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.4.0.dev0) (3.4.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers==4.4.0.dev0) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.4.0.dev0) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.4.0.dev0) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==4.4.0.dev0) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.4.0.dev0) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.4.0.dev0) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.4.0.dev0) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==4.4.0.dev0) (2020.12.5)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.4.0.dev0-cp36-none-any.whl size=1851060 sha256=1943a0f616e28cce581bd0065c4744d535a54a79c696fa20c184f0288d0c90ec\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-nnht1_20/wheels/39/e0/7f/7a0b74120d29e2aec4026870a07526d715b18282287919e3b8\n",
            "Successfully built transformers\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=5d7bcbc5a1b9465f3e1d4d8061542e20c43c55b74d009f6a5dc099338cb760ac\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.4.0.dev0\n",
            "/gdrive/.shortcut-targets-by-id/1rvVQN848IG4yYS2DU7AHiKiDnungjDoK/CV_FinalProject/Dungmn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9eEeWQrg9Rj",
        "outputId": "a607abc3-ab01-4606-8693-9eaf3b42e028"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "!pip install pyvi\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Requirement already satisfied: pyvi in /usr/local/lib/python3.6/dist-packages (0.1)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.6/dist-packages (from pyvi) (0.3.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from pyvi) (0.22.2.post1)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (0.9.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (0.8.7)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (4.41.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RpXMqUPezKJ"
      },
      "source": [
        "# %cd coco/PythonAPI/\r\n",
        "# !make\r\n",
        "# !python setup.py build\r\n",
        "# !python setup.py install\r\n",
        "# %cd ../../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s8xq3qYjGYO"
      },
      "source": [
        "#Build vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5ZLsxBKjRrU",
        "outputId": "caeb8821-7f2d-4ef3-d602-2f87ef43144a"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "build_vocab.py  model.py          \u001b[0m\u001b[01;34mpng\u001b[0m/          requirements.txt\n",
            "\u001b[01;34mdata\u001b[0m/           \u001b[01;34mmodels\u001b[0m/           predict.py    resize.py\n",
            "data_loader.py  \u001b[01;34mmodels_1e4_pyvi\u001b[0m/  \u001b[01;34m__pycache__\u001b[0m/  sample.py\n",
            "download.sh     \u001b[01;34mmodels_raw\u001b[0m/       README.md     train.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGpAvfnkiHZW",
        "outputId": "931d9f2d-efdd-4533-8c2c-a45965527b7f"
      },
      "source": [
        "!python build_vocab.py --caption_path /gdrive/MyDrive/CV_FinalProject/Dungmn/Data/UIT-ViIC/preprocessed_uitviic_captions_train2017.json \\\r\n",
        "--vocab_path data/preprocessed_vocab_.pkl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=1.04s)\n",
            "creating index...\n",
            "index created!\n",
            "[1000/13458] Tokenized the captions.\n",
            "[2000/13458] Tokenized the captions.\n",
            "[3000/13458] Tokenized the captions.\n",
            "[4000/13458] Tokenized the captions.\n",
            "[5000/13458] Tokenized the captions.\n",
            "[6000/13458] Tokenized the captions.\n",
            "[7000/13458] Tokenized the captions.\n",
            "[8000/13458] Tokenized the captions.\n",
            "[9000/13458] Tokenized the captions.\n",
            "[10000/13458] Tokenized the captions.\n",
            "[11000/13458] Tokenized the captions.\n",
            "[12000/13458] Tokenized the captions.\n",
            "[13000/13458] Tokenized the captions.\n",
            "Total vocabulary size: 552\n",
            "Saved the vocabulary wrapper to 'data/preprocessed_vocab_.pkl'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GG_8-YDPbluI"
      },
      "source": [
        "# class Vocabulary(object):\r\n",
        "#     \"\"\"Simple vocabulary wrapper.\"\"\"\r\n",
        "#     def __init__(self):\r\n",
        "#         self.word2idx = {}\r\n",
        "#         self.idx2word = {}\r\n",
        "#         self.idx = 0\r\n",
        "\r\n",
        "#     def add_word(self, word):\r\n",
        "#         if not word in self.word2idx:\r\n",
        "#             self.word2idx[word] = self.idx\r\n",
        "#             self.idx2word[self.idx] = word\r\n",
        "#             self.idx += 1\r\n",
        "\r\n",
        "#     def __call__(self, word):\r\n",
        "#         if not word in self.word2idx:\r\n",
        "#             return self.word2idx['<unk>']\r\n",
        "#         return self.word2idx[word]\r\n",
        "\r\n",
        "#     def __len__(self):\r\n",
        "#         return len(self.word2idx)\r\n",
        "# import pickle\r\n",
        "\r\n",
        "# with open('data/preprocessed_vocab_.pkl','rb') as f:\r\n",
        "#     data = pickle.load(f)\r\n",
        "# data.word2idx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULMb9zvIlpbe",
        "outputId": "01249701-1af3-4d34-9e9e-240ddbb929c9"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "build_vocab.py  download.sh  predict.py    requirements.txt  train.py\n",
            "\u001b[0m\u001b[01;34mdata\u001b[0m/           model.py     \u001b[01;34m__pycache__\u001b[0m/  resize.py\n",
            "data_loader.py  \u001b[01;34mpng\u001b[0m/         README.md     sample.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RkuRENqoWyb"
      },
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8yHOiMcEcWo",
        "outputId": "108829ee-b1ed-4e0a-ab02-6dfb2b323ceb"
      },
      "source": [
        "!python train.py --vocab_path data/preprocessed_vocab_.pkl \\\r\n",
        "--image_dir /gdrive/MyDrive/CV_FinalProject/Dungmn/Data/UIT-ViIC/train_imgs_resized \\\r\n",
        "--caption_path /gdrive/MyDrive/CV_FinalProject/Dungmn/Data/UIT-ViIC/preprocessed_uitviic_captions_train2017.json \\\r\n",
        "--learning_rate 0.0001 --num_epochs 50 --batch_size 512 --save_step 20 \\\r\n",
        "--model_path models \\\r\n",
        "--cp_encoder models/encoder-50-20.ckpt --cp_decoder models/decoder-50-20.ckpt \\\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(batch_size=512, caption_path='/gdrive/MyDrive/CV_FinalProject/Dungmn/Data/UIT-ViIC/preprocessed_uitviic_captions_train2017.json', cp_decoder='models/decoder-50-20.ckpt', cp_encoder='models/encoder-50-20.ckpt', crop_size=224, embed_size=256, hidden_size=512, image_dir='/gdrive/MyDrive/CV_FinalProject/Dungmn/Data/UIT-ViIC/train_imgs_resized', learning_rate=0.0001, log_step=10, model_path='models', num_epochs=50, num_layers=1, num_workers=2, save_step=20, vocab_path='data/preprocessed_vocab_.pkl')\n",
            "loading annotations into memory...\n",
            "Done (t=0.51s)\n",
            "creating index...\n",
            "index created!\n",
            "Load encoder checkpoint models/encoder-50-20.ckpt\n",
            "Load decoder checkpoint models/decoder-50-20.ckpt\n",
            "Epoch [0/50], Step [0/27], Loss: 0.1432, Perplexity: 1.1540\n",
            "Epoch [0/50], Step [10/27], Loss: 0.1483, Perplexity: 1.1598\n",
            "Epoch [0/50], Step [20/27], Loss: 0.1476, Perplexity: 1.1590\n",
            "Epoch [1/50], Step [0/27], Loss: 0.1425, Perplexity: 1.1532\n",
            "Epoch [1/50], Step [10/27], Loss: 0.1425, Perplexity: 1.1531\n",
            "Epoch [1/50], Step [20/27], Loss: 0.1416, Perplexity: 1.1521\n",
            "Epoch [2/50], Step [0/27], Loss: 0.1387, Perplexity: 1.1488\n",
            "Epoch [2/50], Step [10/27], Loss: 0.1434, Perplexity: 1.1542\n",
            "Epoch [2/50], Step [20/27], Loss: 0.1452, Perplexity: 1.1563\n",
            "Epoch [3/50], Step [0/27], Loss: 0.1399, Perplexity: 1.1502\n",
            "Epoch [3/50], Step [10/27], Loss: 0.1409, Perplexity: 1.1513\n",
            "Epoch [3/50], Step [20/27], Loss: 0.1459, Perplexity: 1.1571\n",
            "Epoch [4/50], Step [0/27], Loss: 0.1415, Perplexity: 1.1520\n",
            "Epoch [4/50], Step [10/27], Loss: 0.1403, Perplexity: 1.1506\n",
            "Epoch [4/50], Step [20/27], Loss: 0.1437, Perplexity: 1.1546\n",
            "Epoch [5/50], Step [0/27], Loss: 0.1376, Perplexity: 1.1475\n",
            "Epoch [5/50], Step [10/27], Loss: 0.1454, Perplexity: 1.1566\n",
            "Epoch [5/50], Step [20/27], Loss: 0.1456, Perplexity: 1.1568\n",
            "Epoch [6/50], Step [0/27], Loss: 0.1398, Perplexity: 1.1500\n",
            "Epoch [6/50], Step [10/27], Loss: 0.1418, Perplexity: 1.1524\n",
            "Epoch [6/50], Step [20/27], Loss: 0.1428, Perplexity: 1.1535\n",
            "Epoch [7/50], Step [0/27], Loss: 0.1393, Perplexity: 1.1495\n",
            "Epoch [7/50], Step [10/27], Loss: 0.1389, Perplexity: 1.1491\n",
            "Epoch [7/50], Step [20/27], Loss: 0.1432, Perplexity: 1.1539\n",
            "Epoch [8/50], Step [0/27], Loss: 0.1366, Perplexity: 1.1463\n",
            "Epoch [8/50], Step [10/27], Loss: 0.1406, Perplexity: 1.1510\n",
            "Epoch [8/50], Step [20/27], Loss: 0.1451, Perplexity: 1.1561\n",
            "Epoch [9/50], Step [0/27], Loss: 0.1400, Perplexity: 1.1503\n",
            "Epoch [9/50], Step [10/27], Loss: 0.1383, Perplexity: 1.1483\n",
            "Epoch [9/50], Step [20/27], Loss: 0.1422, Perplexity: 1.1528\n",
            "Epoch [10/50], Step [0/27], Loss: 0.1432, Perplexity: 1.1540\n",
            "Epoch [10/50], Step [10/27], Loss: 0.1406, Perplexity: 1.1510\n",
            "Epoch [10/50], Step [20/27], Loss: 0.1429, Perplexity: 1.1536\n",
            "Epoch [11/50], Step [0/27], Loss: 0.1409, Perplexity: 1.1513\n",
            "Epoch [11/50], Step [10/27], Loss: 0.1446, Perplexity: 1.1556\n",
            "Epoch [11/50], Step [20/27], Loss: 0.1432, Perplexity: 1.1540\n",
            "Epoch [12/50], Step [0/27], Loss: 0.1401, Perplexity: 1.1504\n",
            "Epoch [12/50], Step [10/27], Loss: 0.1397, Perplexity: 1.1499\n",
            "Epoch [12/50], Step [20/27], Loss: 0.1453, Perplexity: 1.1563\n",
            "Epoch [13/50], Step [0/27], Loss: 0.1393, Perplexity: 1.1495\n",
            "Epoch [13/50], Step [10/27], Loss: 0.1440, Perplexity: 1.1549\n",
            "Epoch [13/50], Step [20/27], Loss: 0.1444, Perplexity: 1.1554\n",
            "Epoch [14/50], Step [0/27], Loss: 0.1394, Perplexity: 1.1495\n",
            "Epoch [14/50], Step [10/27], Loss: 0.1411, Perplexity: 1.1515\n",
            "Epoch [14/50], Step [20/27], Loss: 0.1415, Perplexity: 1.1520\n",
            "Epoch [15/50], Step [0/27], Loss: 0.1419, Perplexity: 1.1525\n",
            "Epoch [15/50], Step [10/27], Loss: 0.1396, Perplexity: 1.1498\n",
            "Epoch [15/50], Step [20/27], Loss: 0.1416, Perplexity: 1.1521\n",
            "Epoch [16/50], Step [0/27], Loss: 0.1418, Perplexity: 1.1523\n",
            "Epoch [16/50], Step [10/27], Loss: 0.1450, Perplexity: 1.1560\n",
            "Epoch [16/50], Step [20/27], Loss: 0.1421, Perplexity: 1.1527\n",
            "Epoch [17/50], Step [0/27], Loss: 0.1400, Perplexity: 1.1503\n",
            "Epoch [17/50], Step [10/27], Loss: 0.1390, Perplexity: 1.1492\n",
            "Epoch [17/50], Step [20/27], Loss: 0.1439, Perplexity: 1.1548\n",
            "Epoch [18/50], Step [0/27], Loss: 0.1411, Perplexity: 1.1516\n",
            "Epoch [18/50], Step [10/27], Loss: 0.1462, Perplexity: 1.1574\n",
            "Epoch [18/50], Step [20/27], Loss: 0.1436, Perplexity: 1.1545\n",
            "Epoch [19/50], Step [0/27], Loss: 0.1418, Perplexity: 1.1523\n",
            "Epoch [19/50], Step [10/27], Loss: 0.1455, Perplexity: 1.1566\n",
            "Epoch [19/50], Step [20/27], Loss: 0.1436, Perplexity: 1.1544\n",
            "Epoch [20/50], Step [0/27], Loss: 0.1441, Perplexity: 1.1550\n",
            "Epoch [20/50], Step [10/27], Loss: 0.1404, Perplexity: 1.1507\n",
            "Epoch [20/50], Step [20/27], Loss: 0.1426, Perplexity: 1.1533\n",
            "Epoch [21/50], Step [0/27], Loss: 0.1368, Perplexity: 1.1466\n",
            "Epoch [21/50], Step [10/27], Loss: 0.1415, Perplexity: 1.1520\n",
            "Epoch [21/50], Step [20/27], Loss: 0.1429, Perplexity: 1.1537\n",
            "Epoch [22/50], Step [0/27], Loss: 0.1411, Perplexity: 1.1515\n",
            "Epoch [22/50], Step [10/27], Loss: 0.1390, Perplexity: 1.1492\n",
            "Epoch [22/50], Step [20/27], Loss: 0.1418, Perplexity: 1.1524\n",
            "Epoch [23/50], Step [0/27], Loss: 0.1420, Perplexity: 1.1526\n",
            "Epoch [23/50], Step [10/27], Loss: 0.1417, Perplexity: 1.1522\n",
            "Epoch [23/50], Step [20/27], Loss: 0.1456, Perplexity: 1.1567\n",
            "Epoch [24/50], Step [0/27], Loss: 0.1416, Perplexity: 1.1521\n",
            "Epoch [24/50], Step [10/27], Loss: 0.1408, Perplexity: 1.1512\n",
            "Epoch [24/50], Step [20/27], Loss: 0.1418, Perplexity: 1.1523\n",
            "Epoch [25/50], Step [0/27], Loss: 0.1425, Perplexity: 1.1531\n",
            "Epoch [25/50], Step [10/27], Loss: 0.1431, Perplexity: 1.1539\n",
            "Epoch [25/50], Step [20/27], Loss: 0.1425, Perplexity: 1.1532\n",
            "Epoch [26/50], Step [0/27], Loss: 0.1432, Perplexity: 1.1540\n",
            "Epoch [26/50], Step [10/27], Loss: 0.1397, Perplexity: 1.1499\n",
            "Epoch [26/50], Step [20/27], Loss: 0.1405, Perplexity: 1.1509\n",
            "Epoch [27/50], Step [0/27], Loss: 0.1413, Perplexity: 1.1517\n",
            "Epoch [27/50], Step [10/27], Loss: 0.1444, Perplexity: 1.1553\n",
            "Epoch [27/50], Step [20/27], Loss: 0.1449, Perplexity: 1.1560\n",
            "Epoch [28/50], Step [0/27], Loss: 0.1411, Perplexity: 1.1516\n",
            "Epoch [28/50], Step [10/27], Loss: 0.1401, Perplexity: 1.1504\n",
            "Epoch [28/50], Step [20/27], Loss: 0.1436, Perplexity: 1.1544\n",
            "Epoch [29/50], Step [0/27], Loss: 0.1416, Perplexity: 1.1521\n",
            "Epoch [29/50], Step [10/27], Loss: 0.1410, Perplexity: 1.1514\n",
            "Epoch [29/50], Step [20/27], Loss: 0.1438, Perplexity: 1.1547\n",
            "Epoch [30/50], Step [0/27], Loss: 0.1397, Perplexity: 1.1499\n",
            "Epoch [30/50], Step [10/27], Loss: 0.1367, Perplexity: 1.1465\n",
            "Epoch [30/50], Step [20/27], Loss: 0.1429, Perplexity: 1.1536\n",
            "Epoch [31/50], Step [0/27], Loss: 0.1405, Perplexity: 1.1508\n",
            "Epoch [31/50], Step [10/27], Loss: 0.1437, Perplexity: 1.1545\n",
            "Epoch [31/50], Step [20/27], Loss: 0.1423, Perplexity: 1.1529\n",
            "Epoch [32/50], Step [0/27], Loss: 0.1421, Perplexity: 1.1527\n",
            "Epoch [32/50], Step [10/27], Loss: 0.1430, Perplexity: 1.1537\n",
            "Epoch [32/50], Step [20/27], Loss: 0.1451, Perplexity: 1.1561\n",
            "Epoch [33/50], Step [0/27], Loss: 0.1408, Perplexity: 1.1511\n",
            "Epoch [33/50], Step [10/27], Loss: 0.1389, Perplexity: 1.1491\n",
            "Epoch [33/50], Step [20/27], Loss: 0.1425, Perplexity: 1.1531\n",
            "Epoch [34/50], Step [0/27], Loss: 0.1400, Perplexity: 1.1503\n",
            "Epoch [34/50], Step [10/27], Loss: 0.1390, Perplexity: 1.1491\n",
            "Epoch [34/50], Step [20/27], Loss: 0.1435, Perplexity: 1.1543\n",
            "Epoch [35/50], Step [0/27], Loss: 0.1408, Perplexity: 1.1512\n",
            "Epoch [35/50], Step [10/27], Loss: 0.1440, Perplexity: 1.1549\n",
            "Epoch [35/50], Step [20/27], Loss: 0.1427, Perplexity: 1.1534\n",
            "Epoch [36/50], Step [0/27], Loss: 0.1406, Perplexity: 1.1509\n",
            "Epoch [36/50], Step [10/27], Loss: 0.1392, Perplexity: 1.1493\n",
            "Epoch [36/50], Step [20/27], Loss: 0.1425, Perplexity: 1.1532\n",
            "Epoch [37/50], Step [0/27], Loss: 0.1404, Perplexity: 1.1507\n",
            "Epoch [37/50], Step [10/27], Loss: 0.1409, Perplexity: 1.1513\n",
            "Epoch [37/50], Step [20/27], Loss: 0.1428, Perplexity: 1.1535\n",
            "Epoch [38/50], Step [0/27], Loss: 0.1370, Perplexity: 1.1468\n",
            "Epoch [38/50], Step [10/27], Loss: 0.1398, Perplexity: 1.1501\n",
            "Epoch [38/50], Step [20/27], Loss: 0.1404, Perplexity: 1.1507\n",
            "Epoch [39/50], Step [0/27], Loss: 0.1432, Perplexity: 1.1540\n",
            "Epoch [39/50], Step [10/27], Loss: 0.1405, Perplexity: 1.1509\n",
            "Epoch [39/50], Step [20/27], Loss: 0.1415, Perplexity: 1.1521\n",
            "Epoch [40/50], Step [0/27], Loss: 0.1386, Perplexity: 1.1486\n",
            "Epoch [40/50], Step [10/27], Loss: 0.1443, Perplexity: 1.1553\n",
            "Epoch [40/50], Step [20/27], Loss: 0.1472, Perplexity: 1.1586\n",
            "Epoch [41/50], Step [0/27], Loss: 0.1413, Perplexity: 1.1517\n",
            "Epoch [41/50], Step [10/27], Loss: 0.1408, Perplexity: 1.1512\n",
            "Epoch [41/50], Step [20/27], Loss: 0.1430, Perplexity: 1.1538\n",
            "Epoch [42/50], Step [0/27], Loss: 0.1378, Perplexity: 1.1477\n",
            "Epoch [42/50], Step [10/27], Loss: 0.1409, Perplexity: 1.1514\n",
            "Epoch [42/50], Step [20/27], Loss: 0.1418, Perplexity: 1.1523\n",
            "Epoch [43/50], Step [0/27], Loss: 0.1391, Perplexity: 1.1493\n",
            "Epoch [43/50], Step [10/27], Loss: 0.1410, Perplexity: 1.1514\n",
            "Epoch [43/50], Step [20/27], Loss: 0.1418, Perplexity: 1.1524\n",
            "Epoch [44/50], Step [0/27], Loss: 0.1396, Perplexity: 1.1498\n",
            "Epoch [44/50], Step [10/27], Loss: 0.1413, Perplexity: 1.1518\n",
            "Epoch [44/50], Step [20/27], Loss: 0.1445, Perplexity: 1.1555\n",
            "Epoch [45/50], Step [0/27], Loss: 0.1397, Perplexity: 1.1499\n",
            "Epoch [45/50], Step [10/27], Loss: 0.1397, Perplexity: 1.1499\n",
            "Epoch [45/50], Step [20/27], Loss: 0.1424, Perplexity: 1.1530\n",
            "Epoch [46/50], Step [0/27], Loss: 0.1396, Perplexity: 1.1498\n",
            "Epoch [46/50], Step [10/27], Loss: 0.1407, Perplexity: 1.1511\n",
            "Epoch [46/50], Step [20/27], Loss: 0.1428, Perplexity: 1.1535\n",
            "Epoch [47/50], Step [0/27], Loss: 0.1420, Perplexity: 1.1526\n",
            "Epoch [47/50], Step [10/27], Loss: 0.1414, Perplexity: 1.1519\n",
            "Epoch [47/50], Step [20/27], Loss: 0.1436, Perplexity: 1.1544\n",
            "Epoch [48/50], Step [0/27], Loss: 0.1418, Perplexity: 1.1524\n",
            "Epoch [48/50], Step [10/27], Loss: 0.1403, Perplexity: 1.1506\n",
            "Epoch [48/50], Step [20/27], Loss: 0.1435, Perplexity: 1.1543\n",
            "Epoch [49/50], Step [0/27], Loss: 0.1402, Perplexity: 1.1505\n",
            "Epoch [49/50], Step [10/27], Loss: 0.1388, Perplexity: 1.1490\n",
            "Epoch [49/50], Step [20/27], Loss: 0.1435, Perplexity: 1.1543\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCGcKohtcLV4"
      },
      "source": [
        "#Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Njg5MOj4r1SC",
        "outputId": "d9ee0a98-4a7c-4bc8-bf2d-f41263e794b9"
      },
      "source": [
        "# import json\r\n",
        "# import random\r\n",
        "\r\n",
        "# dataset_path = '/gdrive/MyDrive/CV_FinalProject/Dungmn/Data/UIT-ViIC/'\r\n",
        "# with open(dataset_path + 'uitviic_captions_val2017.json') as f:\r\n",
        "#   train_data = json.load(f)\r\n",
        "\r\n",
        "# id = random.randint(0,len(train_data['images']))\r\n",
        "# print(train_data['images'][id])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'license': 3, 'file_name': '000000527446.jpg', 'coco_url': 'http://images.cocodataset.org/train2017/000000527446.jpg', 'height': 480, 'width': 640, 'date_captured': '2013-11-23 01:12:06', 'flickr_url': 'http://farm7.staticflickr.com/6146/6013833304_3a527a33c2_z.jpg', 'id': 527446}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WF57_CII5Bz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FYujE8xKVTD3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ae55b6e-25de-454b-ae4d-2ba998fcc9c7"
      },
      "source": [
        "!python sample.py --image '$img_test' \\\r\n",
        "--encoder_path models/encoder-50-20.ckpt \\\r\n",
        "--decoder_path models/decoder-50-20.ckpt \\\r\n",
        "--vocab_path data/vocabUIT_v2.pkl \\\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using data/vocabUIT_v2.pkl\n",
            "<start>\n",
            "vận_động_viên\n",
            "tennis\n",
            "đang\n",
            "thi_đấu\n",
            "trên\n",
            "sân\n",
            ".\n",
            "<end>\n",
            "<start> vận_động_viên tennis đang thi_đấu trên sân . <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzq3J2RQGqKK"
      },
      "source": [
        "#Validation Evaluation\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j2t_dQdUKpKK",
        "outputId": "5ad1a653-0968-4157-e333-0bdf3a3e73ea"
      },
      "source": [
        "import nltk\r\n",
        "nltk.download('punkt')\r\n",
        "!pip install pyvi\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Requirement already satisfied: pyvi in /usr/local/lib/python3.6/dist-packages (0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from pyvi) (0.22.2.post1)\n",
            "Requirement already satisfied: sklearn-crfsuite in /usr/local/lib/python3.6/dist-packages (from pyvi) (0.3.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->pyvi) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (1.15.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (0.8.7)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (0.9.7)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-crfsuite->pyvi) (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgzwNqnoGtHJ",
        "outputId": "9421c065-cde1-4f70-8eed-f95ca4ae70e9"
      },
      "source": [
        "!python predict.py --vocab_path data/preprocessed_vocab_.pkl \\\r\n",
        "--encoder_path models/encoder-50-20.ckpt \\\r\n",
        "--decoder_path models/decoder-50-20.ckpt \\\r\n",
        "--image_dir /gdrive/MyDrive/CV_FinalProject/Dungmn/Data/UIT-ViIC/val_imgs_resized \\\r\n",
        "--caption_path /gdrive/MyDrive/CV_FinalProject/Dungmn/Data/UIT-ViIC/uitviic_captions_val2017.json \\\r\n",
        "--result_path /gdrive/MyDrive/CV_FinalProject/Dungmn/result/preprocessed_val_result_Resnet512_LSTM_pyvi.json \\\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using data/preprocessed_vocab_.pkl\n",
            "Done image 0/924\n",
            "Done image 10/924\n",
            "Done image 20/924\n",
            "Done image 30/924\n",
            "Done image 40/924\n",
            "Done image 50/924\n",
            "Done image 60/924\n",
            "Done image 70/924\n",
            "Done image 80/924\n",
            "Done image 90/924\n",
            "Done image 100/924\n",
            "Done image 110/924\n",
            "Done image 120/924\n",
            "Done image 130/924\n",
            "Done image 140/924\n",
            "Done image 150/924\n",
            "Done image 160/924\n",
            "Done image 170/924\n",
            "Done image 180/924\n",
            "Done image 190/924\n",
            "Done image 200/924\n",
            "Done image 210/924\n",
            "Done image 220/924\n",
            "Done image 230/924\n",
            "Done image 240/924\n",
            "Done image 250/924\n",
            "Done image 260/924\n",
            "Done image 270/924\n",
            "Done image 280/924\n",
            "Done image 290/924\n",
            "Done image 300/924\n",
            "Done image 310/924\n",
            "Done image 320/924\n",
            "Done image 330/924\n",
            "Done image 340/924\n",
            "Done image 350/924\n",
            "Done image 360/924\n",
            "Done image 370/924\n",
            "Done image 380/924\n",
            "Done image 390/924\n",
            "Done image 400/924\n",
            "Done image 410/924\n",
            "Done image 420/924\n",
            "Done image 430/924\n",
            "Done image 440/924\n",
            "Done image 450/924\n",
            "Done image 460/924\n",
            "Done image 470/924\n",
            "Done image 480/924\n",
            "Done image 490/924\n",
            "Done image 500/924\n",
            "Done image 510/924\n",
            "Done image 520/924\n",
            "Done image 530/924\n",
            "Done image 540/924\n",
            "Done image 550/924\n",
            "Done image 560/924\n",
            "Done image 570/924\n",
            "Done image 580/924\n",
            "Done image 590/924\n",
            "Done image 600/924\n",
            "Done image 610/924\n",
            "Done image 620/924\n",
            "Done image 630/924\n",
            "Done image 640/924\n",
            "Done image 650/924\n",
            "Done image 660/924\n",
            "Done image 670/924\n",
            "Done image 680/924\n",
            "Done image 690/924\n",
            "Done image 700/924\n",
            "Done image 710/924\n",
            "Done image 720/924\n",
            "Done image 730/924\n",
            "Done image 740/924\n",
            "Done image 750/924\n",
            "Done image 760/924\n",
            "Done image 770/924\n",
            "Done image 780/924\n",
            "Done image 790/924\n",
            "Done image 800/924\n",
            "Done image 810/924\n",
            "Done image 820/924\n",
            "Done image 830/924\n",
            "Done image 840/924\n",
            "Done image 850/924\n",
            "Done image 860/924\n",
            "Done image 870/924\n",
            "Done image 880/924\n",
            "Done image 890/924\n",
            "Done image 900/924\n",
            "Done image 910/924\n",
            "Done image 920/924\n",
            "The result saved at /gdrive/MyDrive/CV_FinalProject/Dungmn/result/preprocessed_val_result_Resnet512_LSTM_pyvi.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7RMrk4aGn9s"
      },
      "source": [
        "#Test Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k21x6_cdngB",
        "outputId": "0a457f24-6d48-4765-dd40-7d6b41a0cfd8"
      },
      "source": [
        "!python predict.py --vocab_path data/preprocessed_vocab_.pkl \\\r\n",
        "--encoder_path models/encoder-50-20.ckpt \\\r\n",
        "--decoder_path models/decoder-50-20.ckpt \\\r\n",
        "--image_dir /gdrive/MyDrive/CV_FinalProject/Dungmn/Data/UIT-ViIC/test_imgs_resized \\\r\n",
        "--caption_path /gdrive/MyDrive/CV_FinalProject/Dungmn/Data/UIT-ViIC/preprocessed_uitviic_captions_test2017.json \\\r\n",
        "--result_path /gdrive/MyDrive/CV_FinalProject/Dungmn/result/preprocessed_test_result_Resnet512_LSTM_pyvi.json \\\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using data/preprocessed_vocab_.pkl\n",
            "Done image 0/231\n",
            "Done image 10/231\n",
            "Done image 20/231\n",
            "Done image 30/231\n",
            "Done image 40/231\n",
            "Done image 50/231\n",
            "Done image 60/231\n",
            "Done image 70/231\n",
            "Done image 80/231\n",
            "Done image 90/231\n",
            "Done image 100/231\n",
            "Done image 110/231\n",
            "Done image 120/231\n",
            "Done image 130/231\n",
            "Done image 140/231\n",
            "Done image 150/231\n",
            "Done image 160/231\n",
            "Done image 170/231\n",
            "Done image 180/231\n",
            "Done image 190/231\n",
            "Done image 200/231\n",
            "Done image 210/231\n",
            "Done image 220/231\n",
            "Done image 230/231\n",
            "The result saved at /gdrive/MyDrive/CV_FinalProject/Dungmn/result/preprocessed_test_result_Resnet512_LSTM_pyvi.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YtBoogNLWA0",
        "outputId": "ab3c0c27-2ccd-4737-f41f-16b11a6f9acd"
      },
      "source": [
        "ls /gdrive/MyDrive/CV_FinalProject/Dungmn/result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "result_Resnet512_LSTM_1e4.json       test_result_Resnet512_LSTM_pyvi.json\n",
            "result_Resnet512_LSTM.json           val_result_Resnet512_LSTM_pyvi.json\n",
            "test_result_Resnet512_LSTM_1e4.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2-kqQTzwpu0"
      },
      "source": [
        "#Resize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1Ln0l-eypzT"
      },
      "source": [
        "!mkdir -p /gdrive/MyDrive/CV_FinalProject/Dungmn/Data/UIT-ViIC/val_img_raw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6FQ6_AQygys"
      },
      "source": [
        "!cp -r /gdrive/MyDrive/CV_FinalProject/Dungmn/Data/UIT-ViIC/val_imgs/*.jpg /gdrive/MyDrive/CV_FinalProject/Dungmn/Data/UIT-ViIC/val_img_raw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82UQfAqm_PRJ"
      },
      "source": [
        "ls /gdrive/MyDrive/CV_FinalProject/Dungmn/Data/UIT-ViIC/train_img_raw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4CwGJxMxidi",
        "outputId": "a4837bd3-e87a-4434-dd08-e53c3cee5289"
      },
      "source": [
        "!python resize.py --image_dir /gdrive/MyDrive/CV_FinalProject/Dungmn/Data/UIT-ViIC/test_imgs \\\r\n",
        "--output_dir /gdrive/MyDrive/CV_FinalProject/Dungmn/Data/UIT-ViIC/test_imgs_resized_224 \\\r\n",
        "--image_size 224"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[100/231] Resized the images and saved into '/gdrive/MyDrive/CV_FinalProject/Dungmn/Data/UIT-ViIC/test_imgs_resized_224'.\n",
            "[200/231] Resized the images and saved into '/gdrive/MyDrive/CV_FinalProject/Dungmn/Data/UIT-ViIC/test_imgs_resized_224'.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lksUmEa1sALg",
        "outputId": "fadef5c9-7049-45d0-d94c-12358b5f46f0"
      },
      "source": [
        "ls /gdrive/MyDrive/CV_FinalProject/Dungmn/Data/UIT-ViIC/test_imgs_resized/*.jpg -1|wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQKna45F2lsG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86221cd6-cf0e-4b19-9a99-058687ca9474"
      },
      "source": [
        "for index, image_data in enumerate(val_data['images'][:2]):\r\n",
        "    print(index,image_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 {'license': 1, 'file_name': '000000230707.jpg', 'coco_url': 'http://images.cocodataset.org/train2017/000000230707.jpg', 'height': 480, 'width': 640, 'date_captured': '2013-11-21 01:19:31', 'flickr_url': 'http://farm9.staticflickr.com/8295/7998077484_c7153e1b24_z.jpg', 'id': 230707}\n",
            "1 {'license': 3, 'file_name': '000000078466.jpg', 'coco_url': 'http://images.cocodataset.org/train2017/000000078466.jpg', 'height': 480, 'width': 640, 'date_captured': '2013-11-21 02:11:39', 'flickr_url': 'http://farm4.staticflickr.com/3723/9502923283_acb2a6471d_z.jpg', 'id': 78466}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBQhTQBkgg52"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}